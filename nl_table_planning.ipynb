{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import GroupKFold, KFold\n",
    "import itertools\n",
    "import functools\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier as rfc\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "#from thundersvm import SVC # need to build library! xcode-select --install then \n",
    "# https://thundersvm.readthedocs.io/en/latest/get-started.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Planning:\n",
    "\n",
    "-ML\n",
    "    -Fix c++ compiler path for Thunder SVM...\n",
    "    -Test vanilla SVM and XGboost\n",
    "\n",
    "-DC\n",
    "    -What are inputs? nl_03 plus: Smiles/RDkit\n",
    "    -Dataset formating: Passing dataset object?\n",
    "    -dataset.X, dataset.y, dataset.w\n",
    "\n",
    "-Profile scripts for slow steps per Lachlan's instructions\n",
    "\n",
    "-Other\n",
    "    -Simple probability of loss from observed data...\n",
    "    -Model from standards only\n",
    "    -Combine model?  Has water then apply ML model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_df = pd.read_pickle('/Users/dis/PycharmProjects/neutral_loss/all_public_output_02.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixes issue that bits column for FP4 fingerprints is list of np.64 instead of \n",
    "# np.array of np.bools\n",
    "# Moveed to end of nl_2_join.py\n",
    "join_df.bits = join_df.bits.apply(lambda x: np.asarray(x, dtype=np.bool))\n",
    "\n",
    "# Check for bad bits (FP4 fingerprints)\n",
    "# 6,115,379 / 6,121,864 are good!\n",
    "def is_1024(x):\n",
    "    if type(x) is np.ndarray and len(x) == 1024:\n",
    "        return np.bool_(1)\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "join_df['good_bits'] = join_df.bits.apply(lambda x: is_1024(x))\n",
    "join_df = join_df.dropna(subset=['good_bits'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6115379, 31)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "join_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_df.to_pickle('/Users/dis/PycharmProjects/neutral_loss/all_public_output_02b.pickle')\n",
    "join_df = pd.read_pickle('/Users/dis/PycharmProjects/neutral_loss/all_public_output_02b.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>polarity</th>\n",
       "      <th>fdr</th>\n",
       "      <th>coloc</th>\n",
       "      <th>mclass</th>\n",
       "      <th>model</th>\n",
       "      <th>X</th>\n",
       "      <th>y</th>\n",
       "      <th>w</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>H2O</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.75</td>\n",
       "      <td>ml</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>mord_norm</td>\n",
       "      <td>n_loss_wparent_H2O</td>\n",
       "      <td>weight</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  target  polarity   fdr  coloc mclass    model          X  \\\n",
       "0    H2O  positive  0.05   0.75     ml  XGBoost  mord_norm   \n",
       "\n",
       "                    y       w  \n",
       "0  n_loss_wparent_H2O  weight  "
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filtering:\n",
    "target = ['H2O'] # ['H2O']\n",
    "polarity = ['positive'] # ['positive', 'negative'] \n",
    "fdrs = [0.05] # [0.2, 0.1, 0.05]\n",
    "colocalizations = [0.75] # [0, 0.5, 0.75]\n",
    "\n",
    "# Outputs (y), and weights (w):\n",
    "global_ys = ['n_loss_only_H2O', 'n_loss_wparent_H2O']\n",
    "global_y = [global_ys[1]]\n",
    "global_w = ['weight']\n",
    "\n",
    "# Class of model:\n",
    "direct_model_on = False\n",
    "ml_model_on = True\n",
    "deepchem_model_on = False\n",
    "\n",
    "# Split.  If true, any formula only appears in train/test/validate.\n",
    "single_fold_group = True\n",
    "\n",
    "ml_df = direct_df = pd.DataFrame(columns=['target', 'polarity', 'fdr', 'coloc',\n",
    "                                       'mclass', 'model', 'X', 'y', 'w'])\n",
    "dc_df = ml_df\n",
    "\n",
    "# Specific inputs (X) for each model:\n",
    "if direct_model_on is True:\n",
    "    model = ['']\n",
    "    Xs = ['trues', 'falses', 'rando', 'H2O_Present', 'n_loss_wparent_H2O']\n",
    "    X =  [Xs[3]\n",
    "    y = global_y\n",
    "    w = global_w\n",
    "    direct_models = list(itertools.product(*[target, polarity, fdrs, colocalizations,\n",
    "                                             ['direct'], model, X, y, w]))\n",
    "    direct_df = pd.DataFrame(direct_models, columns=['target', 'polarity', 'fdr', 'coloc',\n",
    "                                       'mclass', 'model', 'X', 'y', 'w'])\n",
    "\n",
    "if ml_model_on is True:\n",
    "    models = ['random_forest', 'XGBoost', 'ThunderSVM']\n",
    "    model = [models[1]]\n",
    "    Xs = ['bits', 'mord_norm', 'fp_feats'] \n",
    "    X = [Xs[1]]\n",
    "    y = global_y\n",
    "    w = global_w\n",
    "    ml_models = list(itertools.product(*[target, polarity, fdrs, colocalizations,\n",
    "                                         ['ml'], model, X, y, w]))\n",
    "    ml_df = pd.DataFrame(ml_models, columns=['target', 'polarity', 'fdr', 'coloc',\n",
    "                                       'mclass', 'model', 'X', 'y', 'w']) \n",
    "\n",
    "if deepchem_model_on is True:\n",
    "    models = [('GraphConvModel', 'GraphConv'), \n",
    "              ('WeaveModel', 'Weave'), \n",
    "              ('WeaveFeaturizer','Weave') ] \n",
    "    model = [models[0]]    \n",
    "    Xs = ['Molecule', 'Smiles']\n",
    "    X = [Xs[0]]          \n",
    "    y = global_y\n",
    "    w = global_w\n",
    "    dc_models = list(itertools.product(*[target, polarity, fdrs, colocalizations,\n",
    "                                         ['dc'], model, X, y, w]))\n",
    "    dc_df = pd.DataFrame(dc_models, columns=['target', 'polarity', 'fdr', 'coloc',\n",
    "                                       'mclass', 'model', 'X', 'y', 'w'])\n",
    "    \n",
    "filter_param_df = pd.concat([direct_df, ml_df, dc_df]).reset_index(drop=True)\n",
    "filter_param_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanitize(df):\n",
    "    # Drops rows with nans and inconsistent types\n",
    "    df = df.dropna(axis=0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(df, single_fold):\n",
    "    # True: will segregate formulas to one group or another.  Prevents memorization and \n",
    "    # enhances ability to predict new molecues.\n",
    "    # False: is memorization a bad thing over 2900+ datasets?  Extinction plot for novel ID's\n",
    "    # 50:25:25 / Train:Test:Val. Rationale: Chemical space is large.\n",
    "    # Working!\n",
    "\n",
    "    X = df\n",
    "    y = df.y\n",
    "    groups = df.formula\n",
    "\n",
    "    if single_fold is True:\n",
    "        splitter = GroupKFold(n_splits=2)\n",
    "    else:\n",
    "        splitter = KFold(n_splits=2)\n",
    "\n",
    "    group_kfold = GroupKFold(n_splits=2)\n",
    "    for train_ix, tv_ix in splitter.split(X, y, groups):\n",
    "        X_train, X_tv = X.iloc[train_ix, :].copy(deep=True), X.iloc[tv_ix, :].copy(deep=True)\n",
    "\n",
    "    X = X_tv\n",
    "    y = X_tv.y\n",
    "    groups = X_tv.formula\n",
    "\n",
    "    for test_ix, val_ix in splitter.split(X, y, groups):\n",
    "        X_test, X_val = X.iloc[test_ix, :].copy(deep=True), X.iloc[val_ix, :].copy(deep=True)\n",
    "\n",
    "    return [X_train, X_test, X_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confuse(obs_y, theo_y):\n",
    "    # Copy from confuse ipynb\n",
    "    con = confusion_matrix(list(obs_y), list(theo_y))\n",
    "    if con.shape == (1, 1):\n",
    "        print('error!')\n",
    "\n",
    "    elif con.shape == (2, 2):\n",
    "        tn, fp, fn, tp = con.ravel()\n",
    "        sens = tpr = tp / (tp + fn)\n",
    "        spec = tnr = tn / (tn + fp)\n",
    "        f1 = (2 * tp) / (2 * tp + fp + fn)\n",
    "        acc = (tp + tn) / (tp + tn + fp + fn)\n",
    "        confuse = {'tn': tn, 'fp': fp, 'fn': fn, 'tp': tp}\n",
    "        prec = tp / (tp + fp)\n",
    "              \n",
    "        return [acc, {'sens': sens, 'spec': spec, 'f1': f1,\n",
    "                      'test_n': tn + fp + fn + tp, 'test_true': tp + fp,\n",
    "                      'tp': tp, 'tn': tn, 'fp': fp, 'fn': fn\n",
    "                     }]\n",
    "\n",
    "    else:\n",
    "        print('error!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def direct_model(model, dfs):\n",
    "    train_df = dfs[0]\n",
    "    test_df = dfs[1]\n",
    "    \n",
    "    acc_train = confuse(np.array(train_df.y), np.array(train_df.X))[0]\n",
    "    result = confuse(np.array(test_df.y), np.array(test_df.X))\n",
    "    acc_test = result[0]\n",
    "    result_dict = result[1]\n",
    "    result_dict['acc_train'] = acc_train\n",
    "    result_dict['acc_test'] = acc_train\n",
    "                     \n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ml_model(ml_model, dfs):\n",
    "    train_df = dfs[0]  \n",
    "    train_X = train_df.X.to_numpy()\n",
    "    train_X = np.stack(train_X)\n",
    "    train_y = np.array(train_df.y)\n",
    "    train_w = np.array(train_df.w)\n",
    "\n",
    "    test_df = dfs[1]\n",
    "    test_X = test_df.X.to_numpy()\n",
    "    test_X = np.stack(test_X)\n",
    "    test_y = np.array(test_df.y)\n",
    "    test_w = np.array(test_df.w)\n",
    "    \n",
    "    if ml_model is 'random_forest':\n",
    "        # https://stackoverflow.com/questions/30805192/scikit-learn-random-forest-class-weight-and-sample-weight-parameters\n",
    "        # https://scikit-learn.org/stable/auto_examples/svm/plot_weighted_samples.html\n",
    "        clf = rfc(max_features=32, n_estimators=100, random_state=0, \n",
    "                  class_weight=\"balanced\", n_jobs=-1) #\"balanced\"  {0:1,1:5}\n",
    "        \n",
    "    elif ml_model is 'XGBoost':\n",
    "        # https://xgboost.readthedocs.io/en/latest/get_started.html\n",
    "        # https://www.datacamp.com/community/tutorials/xgboost-in-python       \n",
    "        clf = xgb.XGBClassifier('multi:softmax', eta=0.2, min_child_weight=1,\n",
    "                                gamma=0, num_class=1, eval_metric='error')\n",
    "    \n",
    "    elif ml_model is 'ThunderSVM':\n",
    "        # Copied from vanilla scikit SVM parameters\n",
    "        clf = SVC(kernel='linear', C=10, gamma=1)\n",
    "        \n",
    "    model = clf.fit(train_X, train_y, sample_weight=train_w) \n",
    "    acc_train = model.score(train_X, train_y)\n",
    "    acc_test = model.score(test_X, test_y)\n",
    "    predict_y = model.predict(test_X)\n",
    "    result_dict = confuse(test_y, predict_y)[1]\n",
    "    result_dict['acc_train'] = acc_train\n",
    "    result_dict['acc_test'] = acc_train\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    scores = cross_val_score(model, theo_x,\n",
    "                                 obs_y,\n",
    "                                 cats,\n",
    "                                 cv=GroupKFold(n_splits=5)\n",
    "                                 )\n",
    "    cross_a = float(scores.mean())\n",
    "    cross_s = float(scores.std())\n",
    "    '''\n",
    "    \n",
    "    return result_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deep_chem_model(dfs):\n",
    "    # How to call deep chem?\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start 0\n"
     ]
    }
   ],
   "source": [
    "# Make function eventually!\n",
    "\n",
    "# Assumes only one target (e.g. water) at a time!\n",
    "target_fdr = 'fdr_' + target[0]\n",
    "target_coloc = 'colocalization_' + target[0]\n",
    "join_df['best_fdr'] = join_df[['fdr', target_fdr]].min(axis=1)\n",
    "\n",
    "dict_dict = {}\n",
    "for index, row in filter_param_df.iterrows():\n",
    "    print('start ' + str(index))\n",
    "    filtered_df = join_df[(join_df.polarity == row.polarity) &\n",
    "                         (join_df.best_fdr <= row.fdr) &\n",
    "                         ((join_df[target_coloc] >= row.coloc) | (join_df[target_coloc] == 0))\n",
    "                         ]\n",
    "    \n",
    "    xyw_df = filtered_df[['formula', 'hmdb_ids', 'ds_id', row.X, row.y, row.w]].copy(deep=True)    \n",
    "    \n",
    "    if row.X != row.y:\n",
    "        xyw_df = xyw_df.rename(columns={row.X: 'X', row.y: 'y', row.w: 'w'}, inplace=False)\n",
    "    \n",
    "    else:\n",
    "        # Control case with perfect prediction/memorization!\n",
    "        xyw_df['temp_X'] = filtered_df[row.y]\n",
    "        xyw_df['temp_y'] = filtered_df[row.y]\n",
    "        xyw_df = xyw_df[['formula', 'hmdb_ids', 'ds_id', 'temp_X', 'temp_y', row.w]].copy(deep=True)\n",
    "        xyw_df = xyw_df.rename(columns={'temp_X': 'X', 'temp_y': 'y', row.w: 'w'}, inplace=False)\n",
    "        \n",
    "    xyw_df = sanitize(xyw_df)\n",
    "   \n",
    "    split_dfs = split(xyw_df, single_fold_group)\n",
    "    \n",
    "    if row.mclass == 'direct':\n",
    "        result = direct_model(row.model, split_dfs)\n",
    "        all_line = {**dict(row), **result}\n",
    "        dict_dict[index] = all_line\n",
    "        \n",
    "    if row.mclass == 'ml':\n",
    "        result = ml_model(row.model, split_dfs)      \n",
    "        all_line = {**dict(row), **result}\n",
    "        dict_dict[index] = all_line\n",
    "        \n",
    "    if row.mclass == 'dc':\n",
    "        result = dc_model(row.model, split_dfs)\n",
    "        all_line = {**dict(row), **result}\n",
    "        dict_dict[index] = all_line\n",
    "\n",
    "results = pd.DataFrame.from_dict(dict_dict, orient='index')\n",
    "print('Run complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_random_forest = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>polarity</th>\n",
       "      <th>fdr</th>\n",
       "      <th>coloc</th>\n",
       "      <th>mclass</th>\n",
       "      <th>model</th>\n",
       "      <th>X</th>\n",
       "      <th>y</th>\n",
       "      <th>w</th>\n",
       "      <th>sens</th>\n",
       "      <th>spec</th>\n",
       "      <th>f1</th>\n",
       "      <th>test_n</th>\n",
       "      <th>test_true</th>\n",
       "      <th>tp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>acc_train</th>\n",
       "      <th>acc_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>H2O</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.75</td>\n",
       "      <td>ml</td>\n",
       "      <td>random_forest</td>\n",
       "      <td>bits</td>\n",
       "      <td>n_loss_wparent_H2O</td>\n",
       "      <td>weight</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.629</td>\n",
       "      <td>0.197</td>\n",
       "      <td>140476</td>\n",
       "      <td>53618</td>\n",
       "      <td>6622</td>\n",
       "      <td>79834</td>\n",
       "      <td>46996</td>\n",
       "      <td>7024</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>H2O</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.75</td>\n",
       "      <td>ml</td>\n",
       "      <td>random_forest</td>\n",
       "      <td>mord_norm</td>\n",
       "      <td>n_loss_wparent_H2O</td>\n",
       "      <td>weight</td>\n",
       "      <td>0.323</td>\n",
       "      <td>0.896</td>\n",
       "      <td>0.282</td>\n",
       "      <td>140476</td>\n",
       "      <td>17587</td>\n",
       "      <td>4403</td>\n",
       "      <td>113646</td>\n",
       "      <td>13184</td>\n",
       "      <td>9243</td>\n",
       "      <td>0.826</td>\n",
       "      <td>0.826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>H2O</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.75</td>\n",
       "      <td>ml</td>\n",
       "      <td>random_forest</td>\n",
       "      <td>fp_feats</td>\n",
       "      <td>n_loss_wparent_H2O</td>\n",
       "      <td>weight</td>\n",
       "      <td>0.335</td>\n",
       "      <td>0.869</td>\n",
       "      <td>0.262</td>\n",
       "      <td>140476</td>\n",
       "      <td>21230</td>\n",
       "      <td>4570</td>\n",
       "      <td>110170</td>\n",
       "      <td>16660</td>\n",
       "      <td>9076</td>\n",
       "      <td>0.826</td>\n",
       "      <td>0.826</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  target  polarity   fdr  coloc mclass          model          X  \\\n",
       "0    H2O  positive  0.05   0.75     ml  random_forest       bits   \n",
       "1    H2O  positive  0.05   0.75     ml  random_forest  mord_norm   \n",
       "2    H2O  positive  0.05   0.75     ml  random_forest   fp_feats   \n",
       "\n",
       "                    y       w   sens   spec     f1  test_n  test_true    tp  \\\n",
       "0  n_loss_wparent_H2O  weight  0.485  0.629  0.197  140476      53618  6622   \n",
       "1  n_loss_wparent_H2O  weight  0.323  0.896  0.282  140476      17587  4403   \n",
       "2  n_loss_wparent_H2O  weight  0.335  0.869  0.262  140476      21230  4570   \n",
       "\n",
       "       tn     fp    fn  acc_train  acc_test  \n",
       "0   79834  46996  7024      0.768     0.768  \n",
       "1  113646  13184  9243      0.826     0.826  \n",
       "2  110170  16660  9076      0.826     0.826  "
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_random_forest.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
