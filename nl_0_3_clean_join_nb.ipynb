{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will reload modeules after this when they change!\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import functools\n",
    "import importlib\n",
    "import os\n",
    "from IPython.display import Image\n",
    "\n",
    "from nl_00_hmdb_pre import main_loop_0\n",
    "from sklearn.decomposition import PCA\n",
    "import umap\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "import warnings\n",
    "\n",
    "def action_with_warnings():\n",
    "    warnings.warn(\"should not appear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression:\n",
    "from nl_03_filter_model_score_reg import filter_split_model_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary classification:\n",
    "from nl_03_filter_model_score import filter_split_model_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This script runs the neutral loss scripts for MALDI IMS data\n",
    "\n",
    "Steps:\n",
    "1. Generation of core metabolome database.  See:\n",
    "    PycharmProjects/core_metabolome/core_metabolome_db.ipynb\n",
    "2. \n",
    "\n",
    "1. nl_00 Calculates Mordred descriptors and FP4 fingerprints as bits.\n",
    "2. nl_01 Filter HMDB_db for observed and parses METASPACE output.\n",
    "3. nl_02 Joins HMDB_db and METASPACE output.\n",
    "4. nl_03 Filters and searchs with direct and machine learning models.\n",
    "\n",
    "### To do:\n",
    "5. nl_04 deep learning: executing on toy data, change to regression\n",
    "\n",
    "### Observations:\n",
    "1. 2912/3333 datasets a) did not error and b) had at least one id.  \n",
    "2. 2543/2868 datasets w/10 or more ID's.  Obs: 557,508/559,002\n",
    "3. 644,094 values identifications, the dataset with the most identifications had 5,820 and mean was 221 (median 131).  Re calculate...\n",
    "4. The data did not pass the Shapiro-Wilk test for normality, and nonparametrical statistics should be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Off-line steps:\n",
    "### Generation of core metabolome database.\n",
    "http://localhost:8888/notebooks/PycharmProjects/core_metabolome/core_metabolome_db.ipynb\n",
    "### Identification of good quality datasets.\n",
    "http://localhost:8888/notebooks/PycharmProjects/neutral_loss/good_nl_reports/high_quality_data_investigations.ipynb\n",
    "### Good datasets were researched from the beta server.  Run 1x w/ \"reprocess = True\" and \"reprocess_not_downloading = True\".  Run again w/False.\n",
    "http://localhost:8888/notebooks/PycharmProjects/neutral_loss/good_nl_reports/Beta_server_neutral_losses_mass_search.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Off-line variables:\n",
    "core_metabolome = '/Users/dis/PycharmProjects/neutral_loss/good_nl_reports/core_metabolome_v2.pickle'\n",
    "good_ds_ids = '/Users/dis/PycharmProjects/neutral_loss/good_nl_reports/good_ds_2020_Feb_25.txt'\n",
    "beta_variables = {'NEUTRAL_LOSSES': ['-H2O'], 'MAX_FDR': 0.5, 'molDBs': 'core_metabolome_v2'}\n",
    "path_to_reports = 'tbd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Off-line steps:\n",
    "\n",
    "# Generation of core metabolome database.  See:\n",
    "'http://localhost:8888/notebooks/PycharmProjects/core_metabolome/core_metabolome_db.ipynb'\n",
    "core_metabolome = '/Users/dis/PycharmProjects/neutral_loss/good_nl_reports/core_metabolome_v2.pickle'\n",
    "\n",
    "# Identification of good quality datasets.\n",
    "'http://localhost:8888/notebooks/PycharmProjects/neutral_loss/good_nl_reports/high_quality_data_investigations.ipynb'\n",
    "good_ds_ids = '/Users/dis/PycharmProjects/neutral_loss/good_nl_reports/good_ds_2020_Feb_25.txt'\n",
    "\n",
    "# Good datasets were researched from the beta server.  Run 1x w/ \"reprocess = True\" and\n",
    "# \"reprocess_not_downloading = True\".  Run again w/False.  See:\n",
    "'http://localhost:8888/notebooks/PycharmProjects/neutral_loss/good_nl_reports/Beta_server_neutral_losses_mass_search.ipynb'\n",
    "beta_variables = {'NEUTRAL_LOSSES': ['-H2O'], 'MAX_FDR': 0.5, 'molDBs': 'core_metabolome_v2'}\n",
    "path_to_reports = 'tbd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time:\n",
      "\n",
      "16.36795711517334\n",
      "\n",
      "Executed without error\n",
      "\n",
      "databases/core_metabolome_out.pickle\n"
     ]
    }
   ],
   "source": [
    "# nl_00: Generates FP4 descriptors ('bits') and Mordred descriptors. \n",
    "# 900 seconds to reprocess everything on 13k. 15s without reprocessing.\n",
    "\n",
    "db_out_0 = 'databases/core_metabolome_out.pickle'\n",
    "db_in_0 = core_metabolome\n",
    "dfs = main_loop_0(db_out_0, db_in_0, True, False)\n",
    "\n",
    "db_df = dfs[0]\n",
    "bits_df = dfs[1]\n",
    "mord_norm_df = dfs[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n"
     ]
    }
   ],
   "source": [
    "# Merge pickles for each dataset.\n",
    "path_to_reports = '/Users/dis/PycharmProjects/neutral_loss/good_nl_reports/reports'\n",
    "\n",
    "master_df = pd.DataFrame()\n",
    "counter = 0\n",
    "\n",
    "for root, dirs, files in os.walk(path_to_reports):\n",
    "    for file in files:\n",
    "        if file.endswith(\".pickle\"):\n",
    "            if counter % 50 == 0:\n",
    "                print(counter)\n",
    "            counter +=1\n",
    "            current_df = pd.read_pickle(root + '/' + file)\n",
    "            master_df = pd.concat([master_df, current_df], sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datasetId</th>\n",
       "      <th>group</th>\n",
       "      <th>analyzer</th>\n",
       "      <th>polarity</th>\n",
       "      <th>FDR10-v4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2018-10-12_09h21m15s</td>\n",
       "      <td>U Copenhagen</td>\n",
       "      <td>Orbitrap</td>\n",
       "      <td>negative</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>2018-10-12_09h25m16s</td>\n",
       "      <td>U Copenhagen</td>\n",
       "      <td>Orbitrap</td>\n",
       "      <td>negative</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>2018-10-16_09h53m21s</td>\n",
       "      <td>U Copenhagen</td>\n",
       "      <td>Orbitrap</td>\n",
       "      <td>negative</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>2018-10-31_10h26m49s</td>\n",
       "      <td>U Copenhagen</td>\n",
       "      <td>Orbitrap</td>\n",
       "      <td>negative</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2018-11-08_15h29m23s</td>\n",
       "      <td>U Copenhagen</td>\n",
       "      <td>Orbitrap</td>\n",
       "      <td>negative</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3213</td>\n",
       "      <td>2017-01-19_18h32m25s</td>\n",
       "      <td>♡EMBL♡</td>\n",
       "      <td>Orbitrap</td>\n",
       "      <td>negative</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3214</td>\n",
       "      <td>2017-01-25_17h34m34s</td>\n",
       "      <td>♡EMBL♡</td>\n",
       "      <td>Orbitrap</td>\n",
       "      <td>negative</td>\n",
       "      <td>581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3217</td>\n",
       "      <td>2017-01-20_17h52m13s</td>\n",
       "      <td>♡EMBL♡</td>\n",
       "      <td>Orbitrap</td>\n",
       "      <td>negative</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3225</td>\n",
       "      <td>2019-11-28_11h24m47s</td>\n",
       "      <td>♡EMBL♡</td>\n",
       "      <td>Orbitrap</td>\n",
       "      <td>positive</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3229</td>\n",
       "      <td>2019-12-04_00h41m47s</td>\n",
       "      <td>PNNL</td>\n",
       "      <td>FTICR</td>\n",
       "      <td>positive</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>433 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 datasetId         group  analyzer  polarity  FDR10-v4\n",
       "10    2018-10-12_09h21m15s  U Copenhagen  Orbitrap  negative       129\n",
       "11    2018-10-12_09h25m16s  U Copenhagen  Orbitrap  negative       135\n",
       "12    2018-10-16_09h53m21s  U Copenhagen  Orbitrap  negative       115\n",
       "15    2018-10-31_10h26m49s  U Copenhagen  Orbitrap  negative       164\n",
       "20    2018-11-08_15h29m23s  U Copenhagen  Orbitrap  negative       101\n",
       "...                    ...           ...       ...       ...       ...\n",
       "3213  2017-01-19_18h32m25s        ♡EMBL♡  Orbitrap  negative       112\n",
       "3214  2017-01-25_17h34m34s        ♡EMBL♡  Orbitrap  negative       581\n",
       "3217  2017-01-20_17h52m13s        ♡EMBL♡  Orbitrap  negative       216\n",
       "3225  2019-11-28_11h24m47s        ♡EMBL♡  Orbitrap  positive       179\n",
       "3229  2019-12-04_00h41m47s          PNNL     FTICR  positive       160\n",
       "\n",
       "[433 rows x 5 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_id_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Water only.  Edit for cases where neutral losses other than water under investigation.\n",
    "terse_headers_0 = ['formula', 'adduct', 'ds_id', 'has_no_loss', 'has_H2O',\n",
    "                   'msm', 'fdr', 'off_sample', 'hmdb_ids', 'intensity_avg',\n",
    "                   'msm_H2O', 'fdr_H2O', 'off_sample_H2O', 'intensity_avg_H2O',\n",
    "                   'colocalization_H2O', 'loss_intensity_ratio_H2O', 'loss_intensity_share_H2O',\n",
    "                  'ion', 'ion_H2O', 'ion_formula', 'ion_formula_H2O']\n",
    "\n",
    "master_df = master_df[terse_headers_0].copy(deep=True)\n",
    "ds_id_meta = pd.read_pickle('/Users/dis/PycharmProjects/neutral_loss/good_nl_reports/ds_id_meta.pickle')\n",
    "master_df = master_df.merge(ds_id_meta, left_on='ds_id', right_on= 'datasetId', how='left')\n",
    "master_df.drop(columns=['datasetId']).to_pickle('high_quality.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/dis/PycharmProjects/neutral_loss/good_nl_reports/good_ds_2020_Feb_25.txt'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_ds_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploratory data analysis:\n",
    "http://localhost:8888/notebooks/PycharmProjects/neutral_loss/Exploratory_data_analysis.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads pickles from previous step\n",
    "# For QC, don't need to run for reprocess.\n",
    "input_df = pd.read_pickle('high_quality.pickle')\n",
    "hmdb_df = pd.read_pickle('/Users/dis/PycharmProjects/neutral_loss/databases/core_metabolome_out.pickle') # 0.1 Gb\n",
    "mord_norm_df = pd.read_pickle('/Users/dis/PycharmProjects/neutral_loss/databases/mord_norm_df.pickle')  # 0.8 Gb\n",
    "bits_df = pd.read_pickle('/Users/dis/PycharmProjects/neutral_loss/databases/bits_df.pickle')  #0.2 Gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### nl_01 to nl_03 need to be updated after exploratory data analysis is finished!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nl_01: Parses METASPACE output and filters HMDB for observed\n",
    "%run nl_01_preprocess.py -m all_public_data.pickle -p all_public_hmdb.pickle -is_H2O True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads pickles from previous step\n",
    "# For QC, don't need to run for reprocess.\n",
    "output_1 = pd.read_pickle('all_public_data_output_01.pickle')\n",
    "hmdb_1 = pd.read_pickle('all_public_data_hmdb_01.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nl_02: Joins METASPACE output and observed HMDB\n",
    "%run nl_02_join.py --o all_public_data_output_01.pickle --h all_public_data_hmdb_01.pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load X's if running machine learning\n",
    "join_df_path = 'all_public_data_output_02.pickle' \n",
    "join_df = pd.read_pickle(join_df_path)  # 0.5 Gb\n",
    "unique_hmdbs = list(join_df.hmdb_ids.unique())\n",
    "\n",
    "mord_df = pd.read_pickle('mord_norm_hmdb_df.pickle') # 0.2 Gb\n",
    "mord_df = mord_df[mord_df.hmdb_ids.isin(unique_hmdbs)].copy(deep=True)\n",
    "\n",
    "bits_df = pd.read_pickle('bits_hmdb_df.pickle') # 0.8 Gb\n",
    "bits_df = bits_df[bits_df.hmdb_ids.isin(unique_hmdbs)].copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can use this to filter on inferred vaccuum maldi vs ap maldi\n",
    "# ap 1921, vav 1228, all 3248\n",
    "beta_METASPACE = pd.read_csv('Metaspace_beta_2020_Feb.tsv', sep='\\t')\n",
    "inf_source = beta_METASPACE[['datasetId', 'analyzer']].copy(deep=True)\n",
    "\n",
    "all_ds = list(inf_source.datasetId)\n",
    "\n",
    "inf_source = inf_source[(inf_source.analyzer == 'FTICR') |\n",
    "                       (inf_source.analyzer == 'Orbitrap')].copy(deep=True)\n",
    "ap_ds = list(inf_source[inf_source.analyzer == 'Orbitrap'].datasetId)\n",
    "vac_ds = list(inf_source[inf_source.analyzer == 'FTICR'].datasetId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nl_03: Filtering and machine learning models\n",
    "datasets = ['all_ds', 'ap_ds', 'vac_ds']\n",
    "ds_dict = {'all_ds': all_ds, 'ap_ds': ap_ds, 'vac_ds': vac_ds}\n",
    "dataset = [datasets[1]]\n",
    "target = ['H2O'] # ['H2O']\n",
    "polarity = [1] # {1:positive, -1:negative] \n",
    "fdrs = [0.20] # [0.20, 0.10, 0.05]\n",
    "colocalizations = [0.50] # [0.00, 0.50, 0.75]\n",
    "min_n_obs = [10] # [1, 4, 10]\n",
    "one_id_only = [False] # [True, False]\n",
    "\n",
    "# Outputs (y), and weights (w):\n",
    "global_ys = ['n_loss_only_H2O', 'n_loss_wparent_H2O', 'n_loss_all_H2O']\n",
    "y = ['n_loss_wparent_H2O']\n",
    "w = ['weight']\n",
    "w_norms = [False, '10_y_bins', 'n_obs', 'isobar',\n",
    "          '10_y_bins_W_n_obs', '10_y_bins_W_isobar', 'n_obs_W_isobar',\n",
    "          '10_y_bins_W_n_obs_W_isobar']\n",
    "w_norm = ['n_obs']\n",
    "\n",
    "# Class of model:\n",
    "models = ['direct', 'ml', 'deepchem']\n",
    "model = [models[1]]\n",
    "\n",
    "# Split.  If true, any formula only appears in train/test/validate.\n",
    "single_fold_group = True\n",
    "\n",
    "filter_model_df = pd.DataFrame(columns=['target', 'polarity', 'fdr', 'coloc', 'min_n_obs'\n",
    "                                       'model', 'submodel', 'params', 'one_id_only',\n",
    "                                        'X', 'y', 'w'])\n",
    "# Specific inputs (X) for each model:\n",
    "if model[0] is 'direct':\n",
    "    submodel = ['']\n",
    "    params = ['']\n",
    "    Xs = ['trues', 'falses', 'rando', 'H2O_Present', 'n_loss_wparent_H2O']\n",
    "    X = Xs                           \n",
    "elif model[0] is 'ml':\n",
    "    submodels = ['random_forest', 'XGBoost', 'SVM']\n",
    "    submodel = [submodels[1]]\n",
    "    params = ['']\n",
    "    Xs = ['mord_norm', 'bits'] \n",
    "    X = ['mord_norm']\n",
    "elif model[0] is 'deepchem':\n",
    "    submodels = [('GraphConvModel', 'GraphConv'), \n",
    "              ('WeaveModel', 'Weave'), \n",
    "              ('MPNNModel','Weave') ] \n",
    "    submodel = [submodels[0]]    \n",
    "    params = ['']\n",
    "    Xs = ['Molecule', 'Smiles']\n",
    "    X = [Xs[0]]          \n",
    "    \n",
    "model_list = list(itertools.product(*[target, polarity, fdrs, colocalizations, min_n_obs,\n",
    "                                      model, submodel, params, one_id_only,\n",
    "                                      X, y, w, w_norm, dataset]))\n",
    "print()\n",
    "filter_param_df = pd.DataFrame(model_list, columns=['target', 'polarity', 'fdr', 'coloc', 'min_n_obs',\n",
    "                                                    'model', 'submodel', 'params', 'one_id_only',\n",
    "                                                    'X', 'y', 'w', 'w_norm', 'dataset'])\n",
    "\n",
    "filter_param_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_results = filter_split_model_score(filter_param_df, join_df_path, mord_df, bits_df,\n",
    "                                         single_fold_group, ds_dict[dataset[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results.sort_values(by=['rmse_test_w']).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression results:\n",
    "all_model_results = pd.read_pickle('all_model_results.pickle')\n",
    "all_model_results = pd.concat([all_model_results, model_results])\n",
    "all_model_results.to_pickle('all_model_results.pickle')\n",
    "all_model_results.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_model_results.sort_values(by=['rmse_test']).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = dict(all_model_results[(all_model_results.index == 90) & \n",
    "                  (all_model_results.X == 'mord_norm')].round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
